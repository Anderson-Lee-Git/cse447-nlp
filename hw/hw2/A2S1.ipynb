{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oewn7nm0gSo0"
      },
      "source": [
        "# 1. Understanding Attention\n",
        "\n",
        "- Before running the jupyter notebook, don't forget to copy it into your drive **(`File` => `Save a copy in Drive`)**. *Failing to do this step may result in losing the progress of your code.*\n",
        "- For this notebook, please fill in the line(s) directly after a `#TODO` comment with your answers.\n",
        "- For the submission of the assignment, please download this notebook as a **Python file**, named `A2S1.py`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dr9R_7hGvHN"
      },
      "source": [
        "## Imports and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5IgrbAcuGut3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2oro9ZqG3HI",
        "outputId": "b19fc3a2-7845-4628-a815-9034aa90c2a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "key:\n",
            "tensor([[ 0.4700,  0.6500,  0.6000],\n",
            "        [ 0.6400,  0.5000, -0.5900],\n",
            "        [-0.0300, -0.4800, -0.8800],\n",
            "        [ 0.4300, -0.8300,  0.3500]])\n",
            "value:\n",
            "tensor([[-0.0700, -0.8800,  0.4700],\n",
            "        [ 0.3700, -0.9300, -0.0700],\n",
            "        [-0.2500, -0.7500,  0.6100],\n",
            "        [ 0.9400,  0.2000,  0.2800]])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(447)\n",
        "\n",
        "key = torch.randn(4, 3)\n",
        "key /= torch.norm(key, dim=1, keepdim=True)\n",
        "key.round_(decimals=2)\n",
        "\n",
        "value = torch.randn(4, 3)\n",
        "value /= torch.norm(value, dim=1, keepdim=True)\n",
        "value.round_(decimals=2)\n",
        "\n",
        "print(f'key:\\n{key}')\n",
        "print(f'value:\\n{value}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GwAXAX6XHu8A"
      },
      "outputs": [],
      "source": [
        "def attention(query, key, value):\n",
        "    \"\"\"\n",
        "    Note that we remove scaling for simplicity.\n",
        "    \"\"\"\n",
        "    return F.scaled_dot_product_attention(query, key, value, scale=1)\n",
        "\n",
        "\n",
        "def check_query(query, target, key=key, value=value, output=False):\n",
        "    \"\"\"\n",
        "    Helper function for you to check if your query is close to the required target matrix.\n",
        "    \"\"\"\n",
        "    a_out = attention(query, key, value)\n",
        "    if output:\n",
        "        print(f\"attention = {a_out}\")\n",
        "        print(f\"target = {target}\")\n",
        "        print(\"maximum absolute element-wise difference:\", (target - a_out).abs().max())\n",
        "    return (target - a_out).abs().max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J1y16Y7Gix4"
      },
      "source": [
        "## 1.2. Selection via Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bVCedC4XgRf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[44.6093, 28.4705, 31.0986]])\n",
            "attention = tensor([[-0.0700, -0.8800,  0.4700]])\n",
            "target = tensor([-0.0700, -0.8800,  0.4700])\n",
            "maximum absolute element-wise difference: tensor(0.)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define a query vector to ”select” the first value vector\n",
        "\n",
        "# We want to find a scaler, c, such that \n",
        "# exp(c) out weights 1 by a lot. Thus, \n",
        "# the exp(c) / (exp(c) + 3) would be close to 1\n",
        "\n",
        "out = torch.zeros((1, 4))\n",
        "out[0, 0] = 100\n",
        "query121 = torch.linalg.lstsq(key, out.T)[0].T\n",
        "print(query121)\n",
        "check_query(query121, value[0], output=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "OiqQ78tfgRLc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 44.6093,  28.4705,  31.0986],\n",
            "        [ 74.2993,  24.4711, -43.9832],\n",
            "        [  9.9978, -24.5389, -51.8660],\n",
            "        [ 73.9117, -69.2530,  27.8533]])\n",
            "attention = tensor([[-0.0700, -0.8800,  0.4700],\n",
            "        [ 0.3700, -0.9300, -0.0700],\n",
            "        [-0.2500, -0.7500,  0.6100],\n",
            "        [ 0.9400,  0.2000,  0.2800]])\n",
            "target = tensor([[-0.0700, -0.8800,  0.4700],\n",
            "        [ 0.3700, -0.9300, -0.0700],\n",
            "        [-0.2500, -0.7500,  0.6100],\n",
            "        [ 0.9400,  0.2000,  0.2800]])\n",
            "maximum absolute element-wise difference: tensor(0.)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define a query matrix which results in an identity mapping – select all the value vectors\n",
        "\n",
        "# This is the same rationale as previous one\n",
        "# Now we just need an identity function instead\n",
        "out = torch.eye(4, 4) * 100\n",
        "q = torch.linalg.lstsq(key, out.T)\n",
        "query122 = q[0].T\n",
        "# compare output of attention with desired output\n",
        "print(query122)\n",
        "check_query(query122, value, output=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKyVfgcqImGr"
      },
      "source": [
        "## 1.3. Averaging via Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "zaE-R68BMT5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-0., -0., -0.]])\n",
            "attention = tensor([[ 0.2475, -0.5900,  0.3225]])\n",
            "target = tensor([ 0.2475, -0.5900,  0.3225])\n",
            "maximum absolute element-wise difference: tensor(5.9605e-08)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(5.9605e-08)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# define a query vector which averages all the value vectors\n",
        "\n",
        "# The goal is that after softmax, the resulting output \n",
        "# should be equally weighted (1 / 4). And we know \n",
        "# exp(0) is just 1\n",
        "out = torch.zeros((1, 4))\n",
        "q = torch.linalg.lstsq(key, out.T)\n",
        "query131 = q[0].T\n",
        "# compare output of attention with desired output\n",
        "print(query131)\n",
        "target = torch.reshape(value.mean(0, keepdims=True), (3,))  # reshape to a vector\n",
        "check_query(query131, target, output=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jQKXRVuEhgZZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Expected attn before softmax = tensor([[ 3.,  3., -2., -3.]])\n",
            "Expected attn after softmax = tensor([[0.4977, 0.4977, 0.0034, 0.0012]])\n",
            "Actual attn before softmax = tensor([[ 3.1314,  2.9233, -1.8670, -3.0202]])\n",
            "Actual attn after softmax = tensor([[0.5491, 0.4460, 0.0037, 0.0012]])\n",
            "tensor([[ 1.1499,  4.1566, -0.1848]])\n",
            "attention = tensor([[ 0.1267, -0.9006,  0.2295]])\n",
            "target = tensor([ 0.1500, -0.9050,  0.2000])\n",
            "maximum absolute element-wise difference: tensor(0.0295)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(0.0295)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# define a query vector which averages the first two value vectors\n",
        "# We want to out to be equally weighted (1 / 2) for the first two entries\n",
        "# so we make sure to scale up to override the 1's from the last two entries\n",
        "\n",
        "# In addition, we also want to ensure that \n",
        "# query can be solved out properly by considering\n",
        "# the components of key\n",
        "out = torch.zeros((1, 4))\n",
        "out[0, 0] = 3\n",
        "out[0, 1] = 3\n",
        "out[0, 2] = -2\n",
        "out[0, 3] = -3\n",
        "print(f\"Expected attn before softmax = {out}\")\n",
        "print(f\"Expected attn after softmax = {torch.softmax(out, dim=-1)}\")\n",
        "query132 = torch.linalg.lstsq(key, out.T)[0].T\n",
        "print(f\"Actual attn before softmax = {query132 @ key.T}\")\n",
        "print(f\"Actual attn after softmax = {torch.softmax(query132 @ key.T, dim=-1)}\")\n",
        "# compare output of attention with desired output\n",
        "print(query132)\n",
        "\n",
        "target = torch.reshape(value[(0, 1),].mean(0, keepdims=True), (3,))  # reshape to a vector\n",
        "check_query(query132, target, output=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcqbi9hbIqb6"
      },
      "source": [
        "## 1.4. Interactions within Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "5ax_OQnjKxwW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.0271)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define a replacement for only the third key vector k[2] such that the result of attention\n",
        "# with the same unchanged query q from (1.3.2) averages the first three value vectors.\n",
        "m_key = key.clone()\n",
        "\n",
        "# TODO:\n",
        "m_key[2] = key[0]\n",
        "\n",
        "# compare output of attention with desired output\n",
        "check_query(query132, value[(0, 1, 2),].mean(0, keepdims=True), key=m_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "-LF7F1yRJLjK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[-3.0000, -3.0000,  4.3167, -3.0000]])\n",
            "tensor([[6.6302e-04, 6.6302e-04, 9.9801e-01, 6.6302e-04]])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(0.0013)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define a replacement for only the third key vector k[2] such that the result of attention\n",
        "# with the same unchanged query q from (1.3.2) returns the third value vector v[2].\n",
        "m_key = key.clone()\n",
        "\n",
        "# TODO:\n",
        "# A = Q K.T\n",
        "out = torch.zeros((4, 1))\n",
        "out[:2, 0] = -3\n",
        "out[2, 0] = 1\n",
        "out[3:, 0] = -3\n",
        "m_key = torch.linalg.lstsq(query132, out.T)[0].T\n",
        "m_key[2] /= m_key[2].norm()\n",
        "print(query132 @ m_key.T)\n",
        "print(torch.softmax(query132 @ m_key.T, dim=-1))\n",
        "# compare output of attention with desired output\n",
        "check_query(query132, value[2], key=m_key)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
