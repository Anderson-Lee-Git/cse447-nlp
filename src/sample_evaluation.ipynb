{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anderson-Lee-Git/cse447-nlp/blob/main/src/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DKkQBEjz5i_",
        "outputId": "cb4acac4-d526-421f-ca98-cb7ecbfe9d7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (2.2.0)\n",
            "Requirement already satisfied: transformers in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (4.37.2)\n",
            "Requirement already satisfied: datasets in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (2.17.0)\n",
            "Requirement already satisfied: tqdm in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (4.66.1)\n",
            "Requirement already satisfied: gdown==v4.6.3 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (4.6.3)\n",
            "Requirement already satisfied: filelock in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from gdown==v4.6.3) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from gdown==v4.6.3) (2.31.0)\n",
            "Requirement already satisfied: six in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from gdown==v4.6.3) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from gdown==v4.6.3) (4.12.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: sympy in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from torch) (2023.10.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from transformers) (1.26.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from datasets) (15.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from datasets) (2.2.0)\n",
            "Requirement already satisfied: xxhash in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from requests[socks]->gdown==v4.6.3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from requests[socks]->gdown==v4.6.3) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from requests[socks]->gdown==v4.6.3) (2.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from requests[socks]->gdown==v4.6.3) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from beautifulsoup4->gdown==v4.6.3) (2.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from requests[socks]->gdown==v4.6.3) (1.7.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/anderson/Documents/CSE/cse447-nlp/.conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch transformers datasets tqdm gdown==v4.6.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vha4OBQ8z60b",
        "outputId": "59d04534-8265-4316-f467-67432c031318"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/gscratch/scrubbed/lee0618/nlp_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['id', 'question_stem', 'choices', 'answerKey'],\n",
            "    num_rows: 4957\n",
            "})\n",
            "first question sample: The sun is responsible for\n",
            "first choice sample: {'text': ['puppies learning new tricks', 'children growing up and getting old', 'flowers wilting in a vase', 'plants sprouting, blooming and wilting'], 'label': ['A', 'B', 'C', 'D']}\n",
            "first answer key sample: D\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"openbookqa\")\n",
        "dataset_train, dataset_valid, dataset_test = dataset[\"train\"], dataset[\"validation\"], dataset[\"test\"]\n",
        "print(dataset_train)\n",
        "print(f\"first question sample: {dataset_train['question_stem'][0]}\")\n",
        "# Note that choices contains 'text' and 'label' keys\n",
        "print(f\"first choice sample: {dataset_train['choices'][0]}\")\n",
        "print(f\"first answer key sample: {dataset_train['answerKey'][0]}\")\n",
        "# make sure every label ordering in choices is in order ['A', 'B', 'C', 'D']\n",
        "for choice in dataset_train[\"choices\"]:\n",
        "    assert choice[\"label\"] == ['A', 'B', 'C', 'D']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "from datasets import load_dataset\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class OpenQASample:\n",
        "    id: str\n",
        "    question_stem: str\n",
        "    choices: list[str]\n",
        "    labels: list[str]\n",
        "    answer_key: str\n",
        "\n",
        "    @staticmethod\n",
        "    def from_dict(data: dict):\n",
        "        return OpenQASample(\n",
        "            id=data[\"id\"],\n",
        "            question_stem=data[\"question_stem\"],\n",
        "            choices=data[\"choices\"],\n",
        "            labels=data[\"labels\"],\n",
        "            answer_key=data[\"answer_key\"]\n",
        "        )\n",
        "\n",
        "class OpenQADataset(Dataset):\n",
        "    tokenizer: PreTrainedTokenizerFast = None\n",
        "\n",
        "    def __init__(self, split):\n",
        "        self.data = [\n",
        "            OpenQASample(**{\n",
        "                \"id\": raw_sample[\"id\"],\n",
        "                \"question_stem\": raw_sample[\"question_stem\"],\n",
        "                \"choices\": raw_sample[\"choices\"][\"text\"],\n",
        "                \"labels\": raw_sample[\"choices\"][\"label\"],\n",
        "                \"answer_key\": raw_sample[\"answerKey\"]\n",
        "            }) for raw_sample in OpenQADataset.get_openqa(split)\n",
        "        ]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_openqa(split):\n",
        "        dataset = load_dataset(\"openbookqa\")\n",
        "        return dataset[split]\n",
        "    \n",
        "    @staticmethod\n",
        "    def format_question(question):\n",
        "        return question\n",
        "    \n",
        "    @staticmethod\n",
        "    def format_choices(choices, labels):\n",
        "        for i in range(len(choices)):\n",
        "            choices[i] = f\"{labels[i]} - {choices[i]}\"\n",
        "        return choices\n",
        "\n",
        "    @staticmethod\n",
        "    def format_answer_keys(answer_keys):\n",
        "        \"\"\"\n",
        "        Format answer keys from A, B, C, D to 0, 1, 2, 3\n",
        "        :param: list of answer keys in integer\n",
        "        \"\"\"\n",
        "        return [ord(a) - ord(\"A\") for a in answer_keys]\n",
        "    \n",
        "    @staticmethod\n",
        "    def collate_fn(batched_samples):\n",
        "        B = len(batched_samples)\n",
        "        batched_question = [[OpenQADataset.format_question(sample.question_stem)] * 4 for sample in batched_samples]  # B, 4\n",
        "        batched_choices = [OpenQADataset.format_choices(sample.choices, sample.labels) for sample in batched_samples]  # B, 4\n",
        "        batched_answer_key = [sample.answer_key for sample in batched_samples]  # B, 1\n",
        "        # flatten batched_questions for tokenization\n",
        "        batched_question = sum(batched_question, [])\n",
        "        batched_choices = sum(batched_choices, [])\n",
        "        # Tokenize the input texts.\n",
        "        text_encoding = OpenQADataset.tokenizer(batched_question,\n",
        "                                                batched_choices,\n",
        "                                                padding=True,\n",
        "                                                max_length=128,\n",
        "                                                truncation=True,\n",
        "                                                return_tensors=\"pt\")\n",
        "        # unflatten\n",
        "        label_encoding = torch.LongTensor(OpenQADataset.format_answer_keys(batched_answer_key))  # B, 1\n",
        "\n",
        "        return {\n",
        "            \"text_encoding\": {k: v.view(B, 4, -1) for (k, v) in text_encoding.items()},\n",
        "            \"label_encoding\": label_encoding,\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataset import OpenQADataset\n",
        "from transformers import AutoTokenizer, AutoModelForMultipleChoice\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "def compute_accuracy(predictions: torch.Tensor, labels: torch.Tensor) -> float:\n",
        "    accuracy = torch.sum(predictions == labels) / len(predictions)\n",
        "    return accuracy\n",
        "\n",
        "@torch.no_grad\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    for batch in tqdm(dataloader):\n",
        "        text_encoding = batch[\"text_encoding\"]\n",
        "        for k, v in text_encoding.items():\n",
        "            text_encoding[k] = v.to(model.device)\n",
        "        label_encoding = batch[\"label_encoding\"].to(model.device)\n",
        "        out = model(**text_encoding, labels=label_encoding)\n",
        "        logits = out.logits\n",
        "        predictions = torch.argmax(logits, dim=1)\n",
        "        all_predictions += predictions\n",
        "        all_labels += label_encoding\n",
        "    all_predictions = torch.Tensor(all_predictions)\n",
        "    all_labels = torch.Tensor(all_labels)\n",
        "    accuracy = compute_accuracy(all_predictions, all_labels)\n",
        "    print(accuracy)\n",
        "\n",
        "device = \"cuda\"\n",
        "model = AutoModelForMultipleChoice.from_pretrained(\"roberta-base\").to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
        "OpenQADataset.tokenizer = tokenizer\n",
        "dataset_train = OpenQADataset(\"train\")\n",
        "dataloader_train = DataLoader(dataset=dataset_train,\n",
        "                            batch_size=128,\n",
        "                            collate_fn=OpenQADataset.collate_fn)\n",
        "evaluate(model, dataloader_train)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
